{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Albumentation.ipynb",
      "provenance": [],
      "mount_file_id": "1FLM6BFYb1C6Z8nw0BlPN4cnzYOY3jV4H",
      "authorship_tag": "ABX9TyNuUcTCvnCEuW2/j+vv3xd2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TemitopeOladokun/Data-Augmentation/blob/master/Albumentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ertk2JePK9I1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import time\n",
        "import albumentations as A\n",
        " \n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYE_GNNZL1Tx",
        "colab_type": "code",
        "outputId": "2548dfbd-fe6a-4eca-e1db-9f24334a818c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "image_list = glob.glob('/content/drive/My Drive/ABI/Glass/*.jpg')\n",
        "print(len(image_list))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "253\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1iJKlypL1Z7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# custom dataset class for albumentations library\n",
        "  class AlbumentationImageDataset(Dataset):\n",
        "    def __init__(self, image_list):\n",
        "        self.image_list = image_list\n",
        " \n",
        "        self.aug = A.Compose({\n",
        "        A.Resize(200, 300),\n",
        "        A.CenterCrop(100, 100),\n",
        "        A.RandomCrop(80, 80),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Rotate(limit=(-90, 90)),\n",
        "        A.VerticalFlip(p=0.5),\n",
        "        A.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "        })\n",
        "         \n",
        "    def __len__(self):\n",
        "        return (len(self.image_list))\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        image = plt.imread(self.image_list[i])\n",
        "        image = Image.fromarray(image).convert('RGB')\n",
        "        image = self.aug(image=np.array(image))['image']\n",
        "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
        "            \n",
        "        return torch.tensor(image, dtype=torch.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3fGYfBXL1cu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alb_dataset = AlbumentationImageDataset(image_list=image_list)\n",
        "alb_dataloader = DataLoader(dataset=alb_dataset, batch_size=16, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3qT8LqNPs9-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_img(img):\n",
        "    plt.figure(figsize=(18,15))\n",
        "    # unnormalize\n",
        "    img = img / 2 + 0.5  \n",
        "    npimg = img.numpy()\n",
        "    npimg = np.clip(npimg, 0., 1.)\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02wAUFVyPs64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = iter(pytorch_dataloader)\n",
        "images = data.next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oODkV0CqL1XS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# show images\n",
        "show_img(torchvision.utils.make_grid(images))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5JxH-cfL1SU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niKoxuaPL1PY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}